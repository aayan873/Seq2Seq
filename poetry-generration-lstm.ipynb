{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bed224",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c356f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Total characters: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc38c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74f9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = [char2idx[ch] for ch in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf11b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "\n",
    "input_seq = []\n",
    "output_seq = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b1ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text_tokenized) - seq_len):\n",
    "    input_seq.append(text_tokenized[i:i+seq_len])\n",
    "    output_seq.append(text_tokenized[i+seq_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b808952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 100]) torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.tensor(input_seq[20000:70000], dtype=torch.long)\n",
    "y = torch.tensor(output_seq[20000:70000], dtype=torch.long)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2a2924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37e9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, seq_length, char2idx):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "        self.char2idx = char2idx\n",
    "        self.data = [char2idx[c] for c in text]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx:idx+self.seq_length], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx+self.seq_length], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e4e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShakespeareLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embedding(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac850d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "batch_size = 512\n",
    "seq_len = 150\n",
    "num_epochs = 30\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d49f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CharDataset(text, seq_len, char2idx)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b489a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ShakespeareLSTM(vocab_size, embedding_dim, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a2f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6175\n",
      "Epoch 2, Loss: 1.3190\n",
      "Epoch 3, Loss: 1.2428\n",
      "Epoch 4, Loss: 1.1923\n",
      "Epoch 5, Loss: 1.1516\n",
      "Epoch 6, Loss: 1.1152\n",
      "Epoch 7, Loss: 1.0838\n",
      "Epoch 8, Loss: 1.0541\n",
      "Epoch 9, Loss: 1.0255\n",
      "Epoch 10, Loss: 1.0027\n",
      "Epoch 11, Loss: 0.9778\n",
      "Epoch 12, Loss: 0.9572\n",
      "Epoch 13, Loss: 0.9397\n",
      "Epoch 14, Loss: 0.9217\n",
      "Epoch 15, Loss: 0.9085\n",
      "Epoch 16, Loss: 0.8984\n",
      "Epoch 17, Loss: 0.8892\n",
      "Epoch 18, Loss: 0.8771\n",
      "Epoch 19, Loss: 0.8764\n",
      "Epoch 20, Loss: 0.8655\n",
      "Epoch 21, Loss: 0.8647\n",
      "Epoch 22, Loss: 0.8598\n",
      "Epoch 23, Loss: 0.8573\n",
      "Epoch 24, Loss: 0.8607\n",
      "Epoch 25, Loss: 0.8666\n",
      "Epoch 26, Loss: 0.8614\n",
      "Epoch 27, Loss: 0.8614\n",
      "Epoch 28, Loss: 0.8655\n",
      "Epoch 29, Loss: 0.8714\n",
      "Epoch 30, Loss: 0.8768\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.view(-1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, _ = model(X_batch)\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce281ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model, start_text, char2idx, idx2char, length=500, temperature=1.0, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    generated = [c for c in start_text]  # store generated chars\n",
    "\n",
    "    # Convert start_text to tensor\n",
    "    input_seq = torch.tensor([char2idx[c] for c in start_text], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(input_seq, hidden)  # output: [1, vocab_size]\n",
    "            \n",
    "            # Take last step logits directly\n",
    "            output = output.squeeze(0)  # shape: [vocab_size]\n",
    "\n",
    "            # Apply temperature\n",
    "            probs = F.softmax(output / temperature, dim=-1)\n",
    "\n",
    "            # Sample from probability distribution\n",
    "            idx = torch.multinomial(probs, 1).item()\n",
    "            char = idx2char[idx]\n",
    "\n",
    "            generated.append(char)\n",
    "\n",
    "            # Feed the predicted char as next input\n",
    "            input_seq = torch.tensor([[idx]], dtype=torch.long).to(device)\n",
    "\n",
    "    return \"\".join(generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fad3aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "My noble lords,\n",
      "Of whether I have my tongue presently;\n",
      "And so before the corse of true and boldness\n",
      "To Bolingbroke, to take up your bodies sound\n",
      "With thee and grace I hate him from my soldiers.\n",
      "My absence, here and hear my soul and weep!\n",
      "Good world, the king's, and thou art not.\n",
      "\n",
      "BENVOLIO:\n",
      "Mistress, we owe to say the fault's to mother:\n",
      "And so it is more sleep or tears are thus,\n",
      "That in the time shall be thy wife to fly.\n",
      "\n",
      "WARWICK:\n",
      "Thou hast not wed to do some ill him.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Thou dids\n"
     ]
    }
   ],
   "source": [
    "start_text = \"ROMEO:\"\n",
    "generated_text = generate_text(model, start_text, char2idx, idx2char, length=500, temperature=0.8, device=device)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e075a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARWICK:\n",
      "Dyed sleep unsworn, poor-lanched cle.\n",
      "Which negt islead o'cur destroying fire;\n",
      "There's good till Minoly.\n",
      "Now, my Saint George, ebect us thyself,\n",
      "Upon request in much jeholding heart; and, Edward,\n",
      "Will not Italy to make mine ear to flie?\n",
      "Spick loss that full of your deeds are been\n",
      "Beauted.\n",
      "\n",
      "BAPTISTA:\n",
      "Ay, father.\n",
      "This art, my dearh, and if thy foot at home?\n",
      "Yet, baggag-ear, you make a forehalf love:\n",
      "Give no wood-heart of retreaty, bohe not lights.\n",
      "Riarch, sluile, to the tackle; without his Jen;'\n",
      "But, we not so, is upridging told\n",
      "I' hang upon reverent and mild interch\n",
      "Red-ass, Norder Plottenly, unhappy indeed;\n",
      "Pots thy Edward's coast commandeds strong bale tale.\n",
      "At thy ill-skitful and be soy w\n"
     ]
    }
   ],
   "source": [
    "start_text = \"WARWICK:\"\n",
    "generated_text = generate_text(model, start_text, char2idx, idx2char, length=700, temperature=1.5, device=device)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
